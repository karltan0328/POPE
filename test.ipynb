{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pose.dataset import pose_dataset\n",
    "from pose.utils import collate_fn, geodesic_distance, relative_pose_error, aggregate_metrics\n",
    "from pose.model import Mkpts_Reg_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:05<00:04,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/git_project/POPE/data/oneposeplusplus-points/0706-teabox-box\\mkpts0\\820.png-761.png.txt does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:08<00:01,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/git_project/POPE/data/oneposeplusplus-points/0712-insta-others\\mkpts0\\1570.png-125.png.txt does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/git_project/POPE/data/oneposeplusplus-points/0712-insta-others\\mkpts0\\1605.png-185.png.txt does not exist\n",
      "d:/git_project/POPE/data/oneposeplusplus-points/0712-insta-others\\mkpts0\\1628.png-210.png.txt does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'nt':\n",
    "    LM_dataset_path = 'd:/git_project/POPE/data/LM_dataset/'\n",
    "    LM_dataset_json_path = 'd:/git_project/POPE/data/pairs/LINEMOD-test.json'\n",
    "    LM_dataset_points_path = 'd:/git_project/POPE/data/LM_dataset-points/'\n",
    "\n",
    "    onepose_path = 'e:/datasets/OnePose/test_data/'\n",
    "    onepose_json_path = 'd:/git_project/POPE/data/pairs/Onepose-test.json'\n",
    "    onepose_points_path = 'd:/git_project/POPE/data/onepose-points/'\n",
    "\n",
    "    oneposeplusplus_path = 'e:/datasets/OnePose++/lowtexture_test_data/'\n",
    "    oneposeplusplus_json_path = 'd:/git_project/POPE/data/pairs/OneposePlusPlus-test.json'\n",
    "    oneposeplusplus_points_path = 'd:/git_project/POPE/data/oneposeplusplus-points/'\n",
    "elif os.name == 'posix':\n",
    "    LM_dataset_path = 'data/LM_dataset/'\n",
    "    LM_dataset_json_path = 'data/pairs/LINEMOD-test.json'\n",
    "    LM_dataset_points_path = 'data/LM_dataset-points/'\n",
    "\n",
    "    onepose_path = 'data/onepose/'\n",
    "    onepose_json_path = 'data/pairs/Onepose-test.json'\n",
    "    onepose_points_path = 'data/onepose-points/'\n",
    "\n",
    "    oneposeplusplus_path = 'data/oneposeplusplus/'\n",
    "    oneposeplusplus_json_path = 'data/pairs/OneposePlusPlus-test.json'\n",
    "    oneposeplusplus_points_path = 'data/oneposeplusplus-points/'\n",
    "\n",
    "paths = [\n",
    "    # ('linemod', LM_dataset_path, LM_dataset_json_path, LM_dataset_points_path),\n",
    "    # ('onepose', onepose_path, onepose_json_path, onepose_points_path),\n",
    "    ('oneposeplusplus', oneposeplusplus_path, oneposeplusplus_json_path, oneposeplusplus_points_path)\n",
    "]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = pose_dataset(paths)\n",
    "mkpts_max_len, mkpts_sum_len = dataset.get_mkpts_info()\n",
    "\n",
    "\n",
    "random.seed(20231223)\n",
    "torch.manual_seed(20231223)\n",
    "torch.cuda.manual_seed(20231223)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "num_sample = 400\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=False, collate_fn=collate_fn(num_sample))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, drop_last=False, collate_fn=collate_fn(num_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./weights/6d-2023-12-28-20-34-25-0.4200.pth')\n",
    "\n",
    "net.eval()\n",
    "\n",
    "L2 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = dict()\n",
    "metrics.update({'R_errs':[], 't_errs':[], 'inliers':[], \"identifiers\":[]})\n",
    "\n",
    "res_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(test_dataloader):\n",
    "    if i == 1: break\n",
    "    batch_K0 = []\n",
    "    batch_K1 = []\n",
    "    batch_pose0 = []\n",
    "    batch_pose1 = []\n",
    "    batch_mkpts0 = []\n",
    "    batch_mkpts1 = []\n",
    "    batch_pre_K = []\n",
    "    for data in batch:\n",
    "        batch_K0.append(data['K0'])\n",
    "        batch_K1.append(data['K1'])\n",
    "        # print(data['pose0'].shape)\n",
    "        if data['pose0'].shape[0] == 3:\n",
    "            data['pose0'] = np.vstack((data['pose0'], np.array([0, 0, 0, 1])))\n",
    "        if data['pose1'].shape[0] == 3:\n",
    "            data['pose1'] = np.vstack((data['pose1'], np.array([0, 0, 0, 1])))\n",
    "        batch_pose0.append(data['pose0'])\n",
    "        batch_pose1.append(data['pose1'])\n",
    "        batch_mkpts0.append(data['mkpts0'])\n",
    "        batch_mkpts1.append(data['mkpts1'])\n",
    "        batch_pre_K.append(data['pre_K'])\n",
    "    batch_K0 = torch.from_numpy(np.stack(batch_K0, axis=0)).float().to(device)\n",
    "    batch_K1 = torch.from_numpy(np.stack(batch_K1, axis=0)).float().to(device)\n",
    "    batch_pose0 = torch.from_numpy(np.stack(batch_pose0, axis=0)).float().to(device)\n",
    "    batch_pose1 = torch.from_numpy(np.stack(batch_pose1, axis=0)).float().to(device)\n",
    "    batch_mkpts0 = torch.from_numpy(np.stack(batch_mkpts0, axis=0)).float().to(device)\n",
    "    batch_mkpts1 = torch.from_numpy(np.stack(batch_mkpts1, axis=0)).float().to(device)\n",
    "    batch_pre_K = torch.from_numpy(np.stack(batch_pre_K, axis=0)).float().to(device)\n",
    "\n",
    "    batch_relative_pose = torch.matmul(batch_pose1, batch_pose0.permute(0, 2, 1))\n",
    "    # print(batch_relative_pose.shape)\n",
    "\n",
    "    pre_t, pre_rot = net(batch_mkpts0, batch_mkpts1)\n",
    "    # print(pre_t.shape, pre_rot.shape)\n",
    "\n",
    "    # 采用下面的代码进行训练\n",
    "    # gt_t = batch_relative_pose[:, :3, 3]\n",
    "    # gt_rot = batch_relative_pose[:, :3, :3]\n",
    "\n",
    "    # t_loss = L2(gt_t, pre_t)\n",
    "    # rot_loss = geodesic_distance(gt_rot, pre_rot)\n",
    "    # print(t_loss, rot_loss)\n",
    "\n",
    "    # loss = t_loss + rot_loss\n",
    "\n",
    "    # 采用下面的代码进行测试\n",
    "    t_err, R_err = relative_pose_error(batch_relative_pose, pre_rot, pre_t, ignore_gt_t_thr=0.0)\n",
    "    # print(t_err.shape, R_err.shape)\n",
    "    # print(t_err, R_err)\n",
    "    # numpy写法\n",
    "    metrics['t_errs'] = metrics['t_errs'] + np.array(t_err.reshape(-1).cpu().detach().numpy()).tolist()\n",
    "    metrics['R_errs'] = metrics['R_errs'] + np.array(R_err.reshape(-1).cpu().detach().numpy()).tolist()\n",
    "    val_metrics_4tb = aggregate_metrics(metrics, 5e-4)\n",
    "\n",
    "    # R = pre_rot\n",
    "    # R_gt = batch_relative_pose[:, :3, :3]\n",
    "    # bmm = torch.bmm(R.permute(0, 2, 1), R_gt) # (batch, 3, 3)\n",
    "    # bmm_trace = bmm.diagonal(dim1=1, dim2=2).sum(dim=-1).reshape(-1, 1) # (batch, 1)\n",
    "    # cos = (bmm_trace - 1) / 2\n",
    "    # print(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-28 21:26:28.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1m\n",
      "{'R:ACC15': 0.734375,\n",
      " 'R:ACC30': 1.0,\n",
      " 'R:auc@15': 0.6604591690003871,\n",
      " 'R:auc@30': 0.8015627534439166,\n",
      " 'R:medianErr': 0.0,\n",
      " 't:ACC15': 0.953125,\n",
      " 't:ACC30': 1.0,\n",
      " 't:auc@15': 0.5053526592130463,\n",
      " 't:auc@30': 0.7518732218382259,\n",
      " 't:medianErr': 6.47142481803894}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info('\\n' + pprint.pformat(val_metrics_4tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
